# ============================================================
# RAG AI Backend - Production Environment
# ============================================================
# 배포 전 반드시 수정해야 할 항목:
#   1. SECRET_KEY → 새로운 랜덤 키로 변경
#   2. NEO4J_PASSWORD → 강력한 비밀번호로 변경
#   3. CORS_ORIGINS → 실제 서버 IP/도메인으로 변경
#   4. (선택) PostgreSQL 비밀번호 변경 시 DATABASE_URL도 변경
# ============================================================

PROJECT_NAME="RAG AI Backend"
API_V1_STR="/api/v1"

# 환경 설정
# ※ 첫 배포 시 development로 시작 (테이블 자동 생성)
#   테이블 생성 확인 후 production으로 전환
ENVIRONMENT=development
DEBUG=false

# 인증 (반드시 변경!)
SECRET_KEY=SuX3ytvYZL1LSAx-eRE8LeqSVDySr8CbQDrjRzQJfmaTjTcusRY5tnujHQabVPsF
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# ──────────────────────────────────────────────
# 데이터베이스 (Docker 서비스명 사용)
# ──────────────────────────────────────────────
DATABASE_URL=postgresql+asyncpg://rag_user:rag_password@postgres:5432/rag_db
QDRANT_URL=http://qdrant:6333
REDIS_URL=redis://redis:6379
NEO4J_URL=bolt://neo4j:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password

# ──────────────────────────────────────────────
# Ollama (호스트에서 실행 → host.docker.internal)
# ──────────────────────────────────────────────
OLLAMA_BASE_URL=http://host.docker.internal:11434
EMBEDDING_MODEL=BAAI/bge-m3
LLM_MODEL=llama3.1
VISION_MODEL=llava

# ──────────────────────────────────────────────
# CORS (서버 IP/도메인으로 변경!)
# ──────────────────────────────────────────────
CORS_ORIGINS=http://localhost,http://127.0.0.1

# 파일 업로드
MAX_UPLOAD_SIZE_MB=50
ALLOWED_FILE_EXTENSIONS=.pdf,.docx,.doc,.txt,.md,.pptx,.xlsx,.jpg,.jpeg,.png,.gif,.webp

# Rate Limiting
RATE_LIMIT_AUTH_REQUESTS=10
